{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación Práctica de Selección de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Características seleccionadas por chi-cuadrado: Index(['petal length (cm)', 'petal width (cm)'], dtype='object')\n",
      "Características seleccionadas por RFE: Index(['petal length (cm)', 'petal width (cm)'], dtype='object')\n",
      "Características seleccionadas por Random Forest: Index(['petal length (cm)'], dtype='object')\n",
      "[0.10612762 0.02167809 0.43612951 0.43606478]\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Cargar el conjunto de datos de iris\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# Selección de características utilizando el método de chi-cuadrado\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "X_kbest = chi2_selector.fit_transform(X, y)\n",
    "print(f\"Características seleccionadas por chi-cuadrado: {X.columns[chi2_selector.get_support(indices=True)]}\")\n",
    "\n",
    "# Selección de características utilizando Recursive Feature Elimination (RFE)\n",
    "model = LogisticRegression(max_iter=200)\n",
    "rfe_selector = RFE(model, n_features_to_select=2, step=1)\n",
    "rfe_selector = rfe_selector.fit(X, y)\n",
    "print(f\"Características seleccionadas por RFE: {X.columns[rfe_selector.get_support(indices=True)]}\")\n",
    "\n",
    "# Selección de características utilizando Random Forest\n",
    "forest = RandomForestClassifier(random_state=42)\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "important_features = X.columns[importances > np.percentile(importances, 75)]\n",
    "print(f\"Características seleccionadas por Random Forest: {important_features}\")\n",
    "\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación de Métodos de Selección de Características\n",
    " * Filtrado: Rápido y fácil de interpretar, pero puede ser menos preciso porque no considera la interacción entre características.\n",
    " * Wrapper: Más preciso porque evalúa características en el contexto de un modelo, pero es computacionalmente costoso.\n",
    " * Embebido: Ofrece un buen equilibrio entre rendimiento y eficiencia, integrando la selección de características en el proceso de entrenamiento del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
